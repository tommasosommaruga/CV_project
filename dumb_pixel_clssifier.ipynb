{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from utils.labels import trainId2label\n",
    "import os\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Cityscapes dataset\n",
    "CITYSCAPES_DIR = \"data\"\n",
    "IMAGES_DIR = os.path.join(CITYSCAPES_DIR, \"leftImg8bit_trainvaltest/leftImg8bit/train\")\n",
    "LABELS_DIR = os.path.join(CITYSCAPES_DIR, \"gtFine_trainvaltest/gtFine/train\")\n",
    "# Limit the number of images to process\n",
    "LIMIT = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_folders(directory):\n",
    "    \"\"\"Retrieve all city subfolders.\"\"\"\n",
    "    return [os.path.join(directory, city) for city in os.listdir(directory) if os.path.isdir(os.path.join(directory, city))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_label_pairs(images_dir, labels_dir):\n",
    "    \"\"\"Match RGB images with their corresponding label IDs.\"\"\"\n",
    "    image_label_pairs = []\n",
    "    for city_folder in get_city_folders(images_dir):\n",
    "        city_name = os.path.basename(city_folder)\n",
    "        label_city_folder = os.path.join(labels_dir, city_name)\n",
    "\n",
    "        for image_file in os.listdir(city_folder):\n",
    "            if image_file.endswith(\"_leftImg8bit.png\"):\n",
    "                # Image path\n",
    "                image_path = os.path.join(city_folder, image_file)\n",
    "                # Corresponding label file\n",
    "                label_file = image_file.replace(\"_leftImg8bit.png\", \"_gtFine_labelIds.png\")\n",
    "                label_path = os.path.join(label_city_folder, label_file)\n",
    "                if os.path.exists(label_path):\n",
    "                    image_label_pairs.append((image_path, label_path))\n",
    "                    if len(image_label_pairs) >= LIMIT:  # Stop if limit is reached\n",
    "                        return image_label_pairs\n",
    "    return image_label_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image_label_pairs):\n",
    "    \"\"\"Extract pixel RGB values and labels for training.\"\"\"\n",
    "    X = []  # Pixel RGB values\n",
    "    y = []  # Binary labels (road or not road)\n",
    "\n",
    "    for image_path, label_path in image_label_pairs:\n",
    "        # Load RGB image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        # Load label image\n",
    "        label_img = cv2.imread(label_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        # Flatten image and labels into 1D arrays\n",
    "        image_pixels = image.reshape(-1, 3)  # RGB values\n",
    "        label_pixels = label_img.flatten()  # Label IDs\n",
    "        \n",
    "        # Filter for road (TrainId = 7) and not-road\n",
    "        road_mask = (label_pixels == 7)\n",
    "        not_road_mask = ~road_mask\n",
    "        \n",
    "        # Append data\n",
    "        X.extend(image_pixels[road_mask])  # Road pixels\n",
    "        y.extend([1] * np.sum(road_mask))  # Label as road\n",
    "        \n",
    "        X.extend(image_pixels[not_road_mask])  # Non-road pixels\n",
    "        y.extend([0] * np.sum(not_road_mask))  # Label as not-road\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image-label pairs\n",
    "image_label_pairs = get_image_label_pairs(IMAGES_DIR, LABELS_DIR)\n",
    "\n",
    "# Preprocess data\n",
    "X, y = preprocess_data(image_label_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Processed {len(X)} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize RGB values\n",
    "X = X / 255.0  # Scale RGB to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "def load_cityscapes_dataset(images_dir, labels_dir):\n",
    "    images, labels = [], []\n",
    "\n",
    "    for city in os.listdir(images_dir):\n",
    "        city_img_dir = os.path.join(images_dir, city)\n",
    "        city_label_dir = os.path.join(labels_dir, city)\n",
    "        \n",
    "        for img_file in os.listdir(city_img_dir):\n",
    "            if not img_file.endswith(\"_leftImg8bit.png\"):\n",
    "                continue\n",
    "            \n",
    "            # File paths\n",
    "            image_path = os.path.join(city_img_dir, img_file)\n",
    "            label_path = os.path.join(city_label_dir, img_file.replace(\"_leftImg8bit.png\", \"_gtFine_labelIds.png\"))\n",
    "            \n",
    "            # Load and preprocess\n",
    "            image, label = load_image_and_label(image_path, label_path)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cityscapes data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: '/path/to/cityscapes\\\\leftImg8bit/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Cityscapes data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mload_cityscapes_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGES_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLABELS_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Flatten pixels for input-output training\u001b[39;00m\n\u001b[0;32m      6\u001b[0m X_flat \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# RGB for each pixel\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mload_cityscapes_dataset\u001b[1;34m(images_dir, labels_dir)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cityscapes_dataset\u001b[39m(images_dir, labels_dir):\n\u001b[0;32m      3\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      6\u001b[0m         city_img_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(images_dir, city)\n\u001b[0;32m      7\u001b[0m         city_label_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(labels_dir, city)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: '/path/to/cityscapes\\\\leftImg8bit/train'"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "print(\"Loading Cityscapes data...\")\n",
    "X, Y = load_cityscapes_dataset(IMAGES_DIR, LABELS_DIR)\n",
    "\n",
    "# Flatten pixels for input-output training\n",
    "X_flat = X.reshape(-1, 3)  # RGB for each pixel\n",
    "Y_flat = Y.flatten()  # Corresponding binary label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "print(\"Building model...\")\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),  # RGB input\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_flat\u001b[49m, Y_flat, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_flat' is not defined"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "model.fit(X_flat, Y_flat, batch_size=128, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as pixel_classifier.h5\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(\"pixel_classifier.h5\")\n",
    "print(\"Model saved as pixel_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test example\n",
    "def predict_pixel_class(rgb):\n",
    "    prediction = model.predict(np.array([rgb]))\n",
    "    return 1 if prediction > 0.5 else 0\n",
    "\n",
    "print(\"Sample prediction:\", predict_pixel_class([128, 64, 128]))  # Road-like color"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
