{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the relative path to the image\n",
    "image_path = './gtFine_trainvaltest/gtFine/train/aachen/aachen_000000_000019_gtFine_color.png'\n",
    "\n",
    "# Check if the file exists in the specified path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Visualize the image using matplotlib\n",
    "plt.imshow(image_array)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n",
    "\n",
    "# Display basic information about the image array\n",
    "print(\"Image array shape:\", image_array.shape)\n",
    "print(\"Image array dtype:\", image_array.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path to your dataset (adjust as necessary)\n",
    "base_path = './gtFine_trainvaltest/gtFine/train/'\n",
    "\n",
    "# List all cities (directories) in the base train directory\n",
    "cities = os.listdir(base_path)\n",
    "\n",
    "# Loop through each city\n",
    "for city in cities:\n",
    "    city_path = os.path.join(base_path, city)\n",
    "    \n",
    "    if os.path.isdir(city_path):\n",
    "        # List all images in the city's directory (assuming they follow the naming pattern)\n",
    "        image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(city_path, image_file)\n",
    "            instance_path = image_path.replace('_gtFine_color.png', '_gtFine_instanceIds.png')\n",
    "            label_path = image_path.replace('_gtFine_color.png', '_gtFine_labelIds.png')\n",
    "            json_path = image_path.replace('_gtFine_color.png', '_gtFine_polygons.json')\n",
    "\n",
    "            # Open the color image, instance image, and label image\n",
    "            if os.path.exists(image_path):\n",
    "                color_image = Image.open(image_path)\n",
    "                color_array = np.array(color_image)\n",
    "\n",
    "                # Optionally load the instance and label images\n",
    "                instance_image = Image.open(instance_path) if os.path.exists(instance_path) else None\n",
    "                label_image = Image.open(label_path) if os.path.exists(label_path) else None\n",
    "                \n",
    "                # Optionally load the JSON if you need the polygon data\n",
    "                if os.path.exists(json_path):\n",
    "                    with open(json_path) as json_file:\n",
    "                        polygons = json.load(json_file)\n",
    "                \n",
    "                # Visualize the color image (without normalization)\n",
    "                plt.imshow(color_array)  # No need for normalization here\n",
    "                plt.axis('off')  # Hide axes\n",
    "                plt.show()\n",
    "\n",
    "                # Additional processing with instance, label images or polygons can be done here.\n",
    "                \n",
    "                print(f\"Loaded: {image_file}\")\n",
    "            else:\n",
    "                print(f\"Image not found: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "base_path = './gtFine/gtFine/train/'\n",
    "\n",
    "# Define the class ID for 'road' (for example, 'road' has label ID 7 in Cityscapes dataset)\n",
    "road_class_id = 7\n",
    "\n",
    "# Function to load and preprocess image and its binary mask (road vs non-road)\n",
    "def load_data(image_path, label_path, target_size=(256, 256)):\n",
    "    # Check if paths exist (to avoid errors)\n",
    "    if not os.path.exists(image_path) or not os.path.exists(label_path):\n",
    "        raise ValueError(f\"Image or label path does not exist: {image_path}, {label_path}\")\n",
    "    \n",
    "    # Load and resize the image\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0  # Normalize the image to [0, 1]\n",
    "    \n",
    "    # Load the label image (class ID map) and convert it to a binary mask (1 for road, 0 for non-road)\n",
    "    label_image = load_img(label_path, target_size=target_size, color_mode='grayscale')\n",
    "    label_array = img_to_array(label_image)\n",
    "    \n",
    "    # Create a binary mask: 1 for road (ID 7), 0 for non-road\n",
    "    binary_mask = (label_array == road_class_id).astype(np.uint8)\n",
    "    \n",
    "    return image, binary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = './gtFine/gtFine/train/'\n",
    "image_path = os.path.join(base_path, 'aachen/aachen_000000_000019_gtFine_color.png')\n",
    "label_path = os.path.join(base_path, 'aachen/aachen_000000_000019_gtFine_labelIds.png')\n",
    "load_data(image_path, label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to build U-Net model for binary segmentation\n",
    "# def build_unet(input_shape):\n",
    "#     inputs = tf.keras.Input(input_shape)\n",
    "    \n",
    "#     # Encoder (Downsampling)\n",
    "#     c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#     c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "#     p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "#     # Decoder (Upsampling)\n",
    "#     u1 = layers.UpSampling2D((2, 2))(p1)\n",
    "#     u1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "#     u1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "    \n",
    "#     # Output layer (Binary mask)\n",
    "#     outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(u1)  # Binary output (0 or 1)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "#     return model\n",
    "\n",
    "# # Set up your U-Net model\n",
    "# input_shape = (256, 256, 3)  # Adjust this based on your image size\n",
    "# model = build_unet(input_shape)\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Load your training data\n",
    "# def load_all_images_and_labels(base_path, target_size=(256, 256)):\n",
    "#     # Loop through all cities\n",
    "#     cities = os.listdir(base_path)\n",
    "#     X_train, y_train = [], []\n",
    "\n",
    "#     for city in cities:\n",
    "#         city_path = os.path.join(base_path, city)\n",
    "        \n",
    "#         if os.path.isdir(city_path):\n",
    "#             # List all images in the city's directory\n",
    "#             image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "#             for image_file in image_files:\n",
    "#                 image_path = os.path.join(city_path, image_file)\n",
    "#                 label_path = image_path.replace('_gtFine_color.png', '_gtFine_labelIds.png')\n",
    "\n",
    "#                 if os.path.exists(image_path) and os.path.exists(label_path):\n",
    "#                     # Load and preprocess the data\n",
    "#                     image, binary_mask = load_data(image_path, label_path, target_size)\n",
    "#                     X_train.append(image)\n",
    "#                     y_train.append(binary_mask)\n",
    "\n",
    "#     return np.array(X_train), np.array(y_train)\n",
    "\n",
    "# # Load all images and labels for training\n",
    "# X_train, y_train = load_all_images_and_labels(base_path)\n",
    "\n",
    "# # Train the model (adjust epochs and batch size as needed)\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# # Function to make predictions on all images\n",
    "# def predict_on_all_images(base_path, model, target_size=(256, 256)):\n",
    "#     # Loop through all cities again\n",
    "#     cities = os.listdir(base_path)\n",
    "    \n",
    "#     for city in cities:\n",
    "#         city_path = os.path.join(base_path, city)\n",
    "        \n",
    "#         if os.path.isdir(city_path):\n",
    "#             # List all images in the city's directory\n",
    "#             image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "#             for image_file in image_files:\n",
    "#                 image_path = os.path.join(city_path, image_file)\n",
    "\n",
    "#                 if os.path.exists(image_path):\n",
    "#                     # Load and preprocess the image (no need to load the labels for prediction)\n",
    "#                     test_image = load_img(image_path, target_size=target_size)\n",
    "#                     test_image = img_to_array(test_image) / 255.0  # Normalize the image\n",
    "#                     test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "                    \n",
    "#                     # Make the prediction\n",
    "#                     predicted_mask = model.predict(test_image)[0]  # Get the prediction for the first image\n",
    "#                     binary_predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "                    \n",
    "#                     # Visualize or save the predicted binary mask (road vs non-road)\n",
    "#                     plt.imshow(binary_predicted_mask, cmap='gray')\n",
    "#                     plt.title(f\"Predicted Mask for {image_file}\")\n",
    "#                     plt.axis('off')\n",
    "#                     plt.show()\n",
    "\n",
    "# # Use the trained model to make predictions on all images\n",
    "# predict_on_all_images(base_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.ensemble import RandomForestRegressor  # or use XGBRegressor from xgboost\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_images_and_labels(base_path, target_size=(256, 256)):\n",
    "    cities = os.listdir(base_path)\n",
    "    X_train, y_train = [], []\n",
    "\n",
    "    for city in cities:\n",
    "        city_path = os.path.join(base_path, city)\n",
    "        \n",
    "        if os.path.isdir(city_path):\n",
    "            # List all images in the city's directory\n",
    "            image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(city_path, image_file)\n",
    "                label_path = image_path.replace('_gtFine_color.png', '_gtFine_labelIds.png')\n",
    "\n",
    "                if os.path.exists(image_path) and os.path.exists(label_path):\n",
    "                    # Load and preprocess the data\n",
    "                    image, binary_mask = load_data(image_path, label_path, target_size)\n",
    "                    \n",
    "                    # Flatten the image and binary mask for regression\n",
    "                    X_train.append(image.flatten())  # Flatten the image into a 1D vector\n",
    "                    y_train.append(binary_mask.flatten())  # Flatten the mask into a 1D vector\n",
    "\n",
    "    return np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Load all images and labels for training\n",
    "X_train, y_train = load_all_images_and_labels(base_path)\n",
    "\n",
    "# Initialize and train a regression model (e.g., Random Forest Regressor)\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Function to make predictions on all images using the regressor\n",
    "def predict_on_all_images(base_path, model, target_size=(256, 256)):\n",
    "    cities = os.listdir(base_path)\n",
    "    \n",
    "    for city in cities:\n",
    "        city_path = os.path.join(base_path, city)\n",
    "        \n",
    "        if os.path.isdir(city_path):\n",
    "            image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(city_path, image_file)\n",
    "\n",
    "                if os.path.exists(image_path):\n",
    "                    # Load and preprocess the image (no need to load the labels for prediction)\n",
    "                    test_image = load_img(image_path, target_size=target_size)\n",
    "                    test_image = img_to_array(test_image) / 255.0  # Normalize the image\n",
    "                    test_image = test_image.flatten().reshape(1, -1)  # Flatten the image and reshape\n",
    "\n",
    "                    # Make the prediction\n",
    "                    predicted_mask = model.predict(test_image)[0]  # Get the prediction for the first image\n",
    "                    \n",
    "                    # Reshape the prediction back to the original image size (for visualization)\n",
    "                    predicted_mask = predicted_mask.reshape(target_size)  # Reshape back to (256, 256)\n",
    "                    \n",
    "                    # Visualize the predicted binary mask\n",
    "                    binary_predicted_mask = (predicted_mask > 0.5).astype(np.uint8)  # Apply a threshold to get a binary mask\n",
    "                    plt.imshow(binary_predicted_mask, cmap='gray')\n",
    "                    plt.title(f\"Predicted Mask for {image_file}\")\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "# Use the trained model to make predictions on all images\n",
    "predict_on_all_images(base_path, regressor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
