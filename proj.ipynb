{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aachen_000000_000019_leftImg8bit.png\n",
      "aachen_000001_000019_leftImg8bit.png\n",
      "aachen_000002_000019_leftImg8bit.png\n",
      "aachen_000003_000019_leftImg8bit.png\n",
      "aachen_000004_000019_leftImg8bit.png\n",
      "aachen_000005_000019_leftImg8bit.png\n",
      "aachen_000006_000019_leftImg8bit.png\n",
      "aachen_000007_000019_leftImg8bit.png\n",
      "aachen_000008_000019_leftImg8bit.png\n",
      "aachen_000009_000019_leftImg8bit.png\n",
      "aachen_000010_000019_leftImg8bit.png\n",
      "aachen_000011_000019_leftImg8bit.png\n",
      "aachen_000012_000019_leftImg8bit.png\n",
      "aachen_000013_000019_leftImg8bit.png\n",
      "aachen_000014_000019_leftImg8bit.png\n",
      "aachen_000015_000019_leftImg8bit.png\n",
      "aachen_000016_000019_leftImg8bit.png\n",
      "aachen_000017_000019_leftImg8bit.png\n",
      "aachen_000018_000019_leftImg8bit.png\n",
      "aachen_000019_000019_leftImg8bit.png\n",
      "aachen_000020_000019_leftImg8bit.png\n",
      "aachen_000021_000019_leftImg8bit.png\n",
      "aachen_000022_000019_leftImg8bit.png\n",
      "aachen_000023_000019_leftImg8bit.png\n",
      "aachen_000024_000019_leftImg8bit.png\n",
      "aachen_000025_000019_leftImg8bit.png\n",
      "aachen_000026_000019_leftImg8bit.png\n",
      "aachen_000027_000019_leftImg8bit.png\n",
      "aachen_000028_000019_leftImg8bit.png\n",
      "aachen_000029_000019_leftImg8bit.png\n",
      "aachen_000030_000019_leftImg8bit.png\n",
      "aachen_000031_000019_leftImg8bit.png\n",
      "aachen_000032_000019_leftImg8bit.png\n",
      "aachen_000033_000019_leftImg8bit.png\n",
      "aachen_000034_000019_leftImg8bit.png\n",
      "aachen_000035_000019_leftImg8bit.png\n",
      "aachen_000036_000019_leftImg8bit.png\n",
      "aachen_000037_000019_leftImg8bit.png\n",
      "aachen_000038_000019_leftImg8bit.png\n",
      "aachen_000039_000019_leftImg8bit.png\n",
      "aachen_000040_000019_leftImg8bit.png\n",
      "aachen_000041_000019_leftImg8bit.png\n",
      "aachen_000042_000019_leftImg8bit.png\n",
      "aachen_000043_000019_leftImg8bit.png\n",
      "aachen_000044_000019_leftImg8bit.png\n",
      "aachen_000045_000019_leftImg8bit.png\n",
      "aachen_000046_000019_leftImg8bit.png\n",
      "aachen_000047_000019_leftImg8bit.png\n",
      "aachen_000048_000019_leftImg8bit.png\n",
      "aachen_000049_000019_leftImg8bit.png\n",
      "aachen_000050_000019_leftImg8bit.png\n",
      "aachen_000051_000019_leftImg8bit.png\n",
      "aachen_000052_000019_leftImg8bit.png\n",
      "aachen_000053_000019_leftImg8bit.png\n",
      "aachen_000054_000019_leftImg8bit.png\n",
      "aachen_000055_000019_leftImg8bit.png\n",
      "aachen_000056_000019_leftImg8bit.png\n",
      "aachen_000057_000019_leftImg8bit.png\n",
      "aachen_000058_000019_leftImg8bit.png\n",
      "aachen_000059_000019_leftImg8bit.png\n",
      "aachen_000060_000019_leftImg8bit.png\n",
      "aachen_000061_000019_leftImg8bit.png\n",
      "aachen_000062_000019_leftImg8bit.png\n",
      "aachen_000063_000019_leftImg8bit.png\n",
      "aachen_000064_000019_leftImg8bit.png\n",
      "aachen_000065_000019_leftImg8bit.png\n",
      "aachen_000066_000019_leftImg8bit.png\n",
      "aachen_000067_000019_leftImg8bit.png\n",
      "aachen_000068_000019_leftImg8bit.png\n",
      "aachen_000069_000019_leftImg8bit.png\n",
      "aachen_000070_000019_leftImg8bit.png\n",
      "aachen_000071_000019_leftImg8bit.png\n",
      "aachen_000072_000019_leftImg8bit.png\n",
      "aachen_000073_000019_leftImg8bit.png\n",
      "aachen_000074_000019_leftImg8bit.png\n",
      "aachen_000075_000019_leftImg8bit.png\n",
      "aachen_000076_000019_leftImg8bit.png\n",
      "aachen_000077_000019_leftImg8bit.png\n",
      "aachen_000078_000019_leftImg8bit.png\n",
      "aachen_000079_000019_leftImg8bit.png\n",
      "aachen_000080_000019_leftImg8bit.png\n",
      "aachen_000081_000019_leftImg8bit.png\n",
      "aachen_000082_000019_leftImg8bit.png\n",
      "aachen_000083_000019_leftImg8bit.png\n",
      "aachen_000084_000019_leftImg8bit.png\n",
      "aachen_000085_000019_leftImg8bit.png\n",
      "aachen_000086_000019_leftImg8bit.png\n",
      "aachen_000087_000019_leftImg8bit.png\n",
      "aachen_000088_000019_leftImg8bit.png\n",
      "aachen_000089_000019_leftImg8bit.png\n",
      "aachen_000090_000019_leftImg8bit.png\n",
      "aachen_000091_000019_leftImg8bit.png\n",
      "aachen_000092_000019_leftImg8bit.png\n",
      "aachen_000093_000019_leftImg8bit.png\n",
      "aachen_000094_000019_leftImg8bit.png\n",
      "aachen_000095_000019_leftImg8bit.png\n",
      "aachen_000096_000019_leftImg8bit.png\n",
      "aachen_000097_000019_leftImg8bit.png\n",
      "aachen_000098_000019_leftImg8bit.png\n",
      "aachen_000099_000019_leftImg8bit.png\n",
      "aachen_000100_000019_leftImg8bit.png\n",
      "aachen_000101_000019_leftImg8bit.png\n",
      "aachen_000102_000019_leftImg8bit.png\n",
      "aachen_000103_000019_leftImg8bit.png\n",
      "aachen_000104_000019_leftImg8bit.png\n",
      "aachen_000105_000019_leftImg8bit.png\n",
      "aachen_000106_000019_leftImg8bit.png\n",
      "aachen_000107_000019_leftImg8bit.png\n",
      "aachen_000108_000019_leftImg8bit.png\n",
      "aachen_000109_000019_leftImg8bit.png\n",
      "aachen_000110_000019_leftImg8bit.png\n",
      "aachen_000111_000019_leftImg8bit.png\n",
      "aachen_000112_000019_leftImg8bit.png\n",
      "aachen_000113_000019_leftImg8bit.png\n",
      "aachen_000114_000019_leftImg8bit.png\n",
      "aachen_000115_000019_leftImg8bit.png\n",
      "aachen_000116_000019_leftImg8bit.png\n",
      "aachen_000117_000019_leftImg8bit.png\n",
      "aachen_000118_000019_leftImg8bit.png\n",
      "aachen_000119_000019_leftImg8bit.png\n",
      "aachen_000120_000019_leftImg8bit.png\n",
      "aachen_000121_000019_leftImg8bit.png\n",
      "aachen_000122_000019_leftImg8bit.png\n",
      "aachen_000123_000019_leftImg8bit.png\n",
      "aachen_000124_000019_leftImg8bit.png\n",
      "aachen_000125_000019_leftImg8bit.png\n",
      "aachen_000126_000019_leftImg8bit.png\n",
      "aachen_000127_000019_leftImg8bit.png\n",
      "aachen_000128_000019_leftImg8bit.png\n",
      "aachen_000129_000019_leftImg8bit.png\n",
      "aachen_000130_000019_leftImg8bit.png\n",
      "aachen_000131_000019_leftImg8bit.png\n",
      "aachen_000132_000019_leftImg8bit.png\n",
      "aachen_000133_000019_leftImg8bit.png\n",
      "aachen_000134_000019_leftImg8bit.png\n",
      "aachen_000135_000019_leftImg8bit.png\n",
      "aachen_000136_000019_leftImg8bit.png\n",
      "aachen_000137_000019_leftImg8bit.png\n",
      "aachen_000138_000019_leftImg8bit.png\n",
      "aachen_000139_000019_leftImg8bit.png\n",
      "aachen_000140_000019_leftImg8bit.png\n",
      "aachen_000141_000019_leftImg8bit.png\n",
      "aachen_000142_000019_leftImg8bit.png\n",
      "aachen_000143_000019_leftImg8bit.png\n",
      "aachen_000144_000019_leftImg8bit.png\n",
      "aachen_000145_000019_leftImg8bit.png\n",
      "aachen_000146_000019_leftImg8bit.png\n",
      "aachen_000147_000019_leftImg8bit.png\n",
      "aachen_000148_000019_leftImg8bit.png\n",
      "aachen_000149_000019_leftImg8bit.png\n",
      "aachen_000150_000019_leftImg8bit.png\n",
      "aachen_000151_000019_leftImg8bit.png\n",
      "aachen_000152_000019_leftImg8bit.png\n",
      "aachen_000153_000019_leftImg8bit.png\n",
      "aachen_000154_000019_leftImg8bit.png\n",
      "aachen_000155_000019_leftImg8bit.png\n",
      "aachen_000156_000019_leftImg8bit.png\n",
      "aachen_000157_000019_leftImg8bit.png\n",
      "aachen_000158_000019_leftImg8bit.png\n",
      "aachen_000159_000019_leftImg8bit.png\n",
      "aachen_000160_000019_leftImg8bit.png\n",
      "aachen_000161_000019_leftImg8bit.png\n",
      "aachen_000162_000019_leftImg8bit.png\n",
      "aachen_000163_000019_leftImg8bit.png\n",
      "aachen_000164_000019_leftImg8bit.png\n",
      "aachen_000165_000019_leftImg8bit.png\n",
      "aachen_000166_000019_leftImg8bit.png\n",
      "aachen_000167_000019_leftImg8bit.png\n",
      "aachen_000168_000019_leftImg8bit.png\n",
      "aachen_000169_000019_leftImg8bit.png\n",
      "aachen_000170_000019_leftImg8bit.png\n",
      "aachen_000171_000019_leftImg8bit.png\n",
      "aachen_000172_000019_leftImg8bit.png\n",
      "aachen_000173_000019_leftImg8bit.png\n"
     ]
    }
   ],
   "source": [
    "# print file names in folder\n",
    "def print_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        print(filename)\n",
    "\n",
    "folder = \"data/leftImg8bit_trainvaltest/leftImg8bit/train/aachen\"\n",
    "print_files(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the relative path to the image\n",
    "image_path = './gtFine_trainvaltest/gtFine/train/aachen/aachen_000000_000019_gtFine_color.png'\n",
    "\n",
    "# Check if the file exists in the specified path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Visualize the image using matplotlib\n",
    "plt.imshow(image_array)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n",
    "\n",
    "# Display basic information about the image array\n",
    "print(\"Image array shape:\", image_array.shape)\n",
    "print(\"Image array dtype:\", image_array.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path to your dataset (adjust as necessary)\n",
    "base_path = './gtFine_trainvaltest/gtFine/train/'\n",
    "\n",
    "# List all cities (directories) in the base train directory\n",
    "cities = os.listdir(base_path)\n",
    "\n",
    "# Loop through each city\n",
    "for city in cities:\n",
    "    city_path = os.path.join(base_path, city)\n",
    "    \n",
    "    if os.path.isdir(city_path):\n",
    "        # List all images in the city's directory (assuming they follow the naming pattern)\n",
    "        image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(city_path, image_file)\n",
    "            instance_path = image_path.replace('_gtFine_color.png', '_gtFine_instanceIds.png')\n",
    "            label_path = image_path.replace('_gtFine_color.png', '_gtFine_labelIds.png')\n",
    "            json_path = image_path.replace('_gtFine_color.png', '_gtFine_polygons.json')\n",
    "\n",
    "            # Open the color image, instance image, and label image\n",
    "            if os.path.exists(image_path):\n",
    "                color_image = Image.open(image_path)\n",
    "                color_array = np.array(color_image)\n",
    "\n",
    "                # Optionally load the instance and label images\n",
    "                instance_image = Image.open(instance_path) if os.path.exists(instance_path) else None\n",
    "                label_image = Image.open(label_path) if os.path.exists(label_path) else None\n",
    "                \n",
    "                # Optionally load the JSON if you need the polygon data\n",
    "                if os.path.exists(json_path):\n",
    "                    with open(json_path) as json_file:\n",
    "                        polygons = json.load(json_file)\n",
    "                \n",
    "                # Visualize the color image (without normalization)\n",
    "                plt.imshow(color_array)  # No need for normalization here\n",
    "                plt.axis('off')  # Hide axes\n",
    "                plt.show()\n",
    "\n",
    "                # Additional processing with instance, label images or polygons can be done here.\n",
    "                \n",
    "                print(f\"Loaded: {image_file}\")\n",
    "            else:\n",
    "                print(f\"Image not found: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "base_path = './gtFine/gtFine/train/'\n",
    "\n",
    "# Define the class ID for 'road' (for example, 'road' has label ID 7 in Cityscapes dataset)\n",
    "road_class_id = 7\n",
    "\n",
    "# Function to load and preprocess image and its binary mask (road vs non-road)\n",
    "def load_data(image_path, label_path, target_size=(256, 256)):\n",
    "    # Check if paths exist (to avoid errors)\n",
    "    if not os.path.exists(image_path) or not os.path.exists(label_path):\n",
    "        raise ValueError(f\"Image or label path does not exist: {image_path}, {label_path}\")\n",
    "    \n",
    "    # Load and resize the image\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0  # Normalize the image to [0, 1]\n",
    "    \n",
    "    # Load the label image (class ID map) and convert it to a binary mask (1 for road, 0 for non-road)\n",
    "    label_image = load_img(label_path, target_size=target_size, color_mode='grayscale')\n",
    "    label_array = img_to_array(label_image)\n",
    "    \n",
    "    # Create a binary mask: 1 for road (ID 7), 0 for non-road\n",
    "    binary_mask = (label_array == road_class_id).astype(np.uint8)\n",
    "    \n",
    "    return image, binary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = './gtFine/gtFine/train/'\n",
    "image_path = os.path.join(base_path, 'aachen/aachen_000000_000019_gtFine_color.png')\n",
    "label_path = os.path.join(base_path, 'aachen/aachen_000000_000019_gtFine_labelIds.png')\n",
    "load_data(image_path, label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to build U-Net model for binary segmentation\n",
    "# def build_unet(input_shape):\n",
    "#     inputs = tf.keras.Input(input_shape)\n",
    "    \n",
    "#     # Encoder (Downsampling)\n",
    "#     c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#     c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "#     p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "#     # Decoder (Upsampling)\n",
    "#     u1 = layers.UpSampling2D((2, 2))(p1)\n",
    "#     u1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "#     u1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "    \n",
    "#     # Output layer (Binary mask)\n",
    "#     outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(u1)  # Binary output (0 or 1)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "#     return model\n",
    "\n",
    "# # Set up your U-Net model\n",
    "# input_shape = (256, 256, 3)  # Adjust this based on your image size\n",
    "# model = build_unet(input_shape)\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Load your training data\n",
    "# def load_all_images_and_labels(base_path, target_size=(256, 256)):\n",
    "#     # Loop through all cities\n",
    "#     cities = os.listdir(base_path)\n",
    "#     X_train, y_train = [], []\n",
    "\n",
    "#     for city in cities:\n",
    "#         city_path = os.path.join(base_path, city)\n",
    "        \n",
    "#         if os.path.isdir(city_path):\n",
    "#             # List all images in the city's directory\n",
    "#             image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "#             for image_file in image_files:\n",
    "#                 image_path = os.path.join(city_path, image_file)\n",
    "#                 label_path = image_path.replace('_gtFine_color.png', '_gtFine_labelIds.png')\n",
    "\n",
    "#                 if os.path.exists(image_path) and os.path.exists(label_path):\n",
    "#                     # Load and preprocess the data\n",
    "#                     image, binary_mask = load_data(image_path, label_path, target_size)\n",
    "#                     X_train.append(image)\n",
    "#                     y_train.append(binary_mask)\n",
    "\n",
    "#     return np.array(X_train), np.array(y_train)\n",
    "\n",
    "# # Load all images and labels for training\n",
    "# X_train, y_train = load_all_images_and_labels(base_path)\n",
    "\n",
    "# # Train the model (adjust epochs and batch size as needed)\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# # Function to make predictions on all images\n",
    "# def predict_on_all_images(base_path, model, target_size=(256, 256)):\n",
    "#     # Loop through all cities again\n",
    "#     cities = os.listdir(base_path)\n",
    "    \n",
    "#     for city in cities:\n",
    "#         city_path = os.path.join(base_path, city)\n",
    "        \n",
    "#         if os.path.isdir(city_path):\n",
    "#             # List all images in the city's directory\n",
    "#             image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "#             for image_file in image_files:\n",
    "#                 image_path = os.path.join(city_path, image_file)\n",
    "\n",
    "#                 if os.path.exists(image_path):\n",
    "#                     # Load and preprocess the image (no need to load the labels for prediction)\n",
    "#                     test_image = load_img(image_path, target_size=target_size)\n",
    "#                     test_image = img_to_array(test_image) / 255.0  # Normalize the image\n",
    "#                     test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "                    \n",
    "#                     # Make the prediction\n",
    "#                     predicted_mask = model.predict(test_image)[0]  # Get the prediction for the first image\n",
    "#                     binary_predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "                    \n",
    "#                     # Visualize or save the predicted binary mask (road vs non-road)\n",
    "#                     plt.imshow(binary_predicted_mask, cmap='gray')\n",
    "#                     plt.title(f\"Predicted Mask for {image_file}\")\n",
    "#                     plt.axis('off')\n",
    "#                     plt.show()\n",
    "\n",
    "# # Use the trained model to make predictions on all images\n",
    "# predict_on_all_images(base_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.ensemble import RandomForestRegressor  # or use XGBRegressor from xgboost\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_images_and_labels(base_path, target_size=(256, 256)):\n",
    "    cities = os.listdir(base_path)\n",
    "    X_train, y_train = [], []\n",
    "\n",
    "    for city in cities:\n",
    "        city_path = os.path.join(base_path, city)\n",
    "        \n",
    "        if os.path.isdir(city_path):\n",
    "            # List all images in the city's directory\n",
    "            image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(city_path, image_file)\n",
    "                label_path = image_path.replace('_gtFine_color.png', '_gtFine_labelIds.png')\n",
    "\n",
    "                if os.path.exists(image_path) and os.path.exists(label_path):\n",
    "                    # Load and preprocess the data\n",
    "                    image, binary_mask = load_data(image_path, label_path, target_size)\n",
    "                    \n",
    "                    # Flatten the image and binary mask for regression\n",
    "                    X_train.append(image.flatten())  # Flatten the image into a 1D vector\n",
    "                    y_train.append(binary_mask.flatten())  # Flatten the mask into a 1D vector\n",
    "\n",
    "    return np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Load all images and labels for training\n",
    "X_train, y_train = load_all_images_and_labels(base_path)\n",
    "\n",
    "# Initialize and train a regression model (e.g., Random Forest Regressor)\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Function to make predictions on all images using the regressor\n",
    "def predict_on_all_images(base_path, model, target_size=(256, 256)):\n",
    "    cities = os.listdir(base_path)\n",
    "    \n",
    "    for city in cities:\n",
    "        city_path = os.path.join(base_path, city)\n",
    "        \n",
    "        if os.path.isdir(city_path):\n",
    "            image_files = [f for f in os.listdir(city_path) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(city_path, image_file)\n",
    "\n",
    "                if os.path.exists(image_path):\n",
    "                    # Load and preprocess the image (no need to load the labels for prediction)\n",
    "                    test_image = load_img(image_path, target_size=target_size)\n",
    "                    test_image = img_to_array(test_image) / 255.0  # Normalize the image\n",
    "                    test_image = test_image.flatten().reshape(1, -1)  # Flatten the image and reshape\n",
    "\n",
    "                    # Make the prediction\n",
    "                    predicted_mask = model.predict(test_image)[0]  # Get the prediction for the first image\n",
    "                    \n",
    "                    # Reshape the prediction back to the original image size (for visualization)\n",
    "                    predicted_mask = predicted_mask.reshape(target_size)  # Reshape back to (256, 256)\n",
    "                    \n",
    "                    # Visualize the predicted binary mask\n",
    "                    binary_predicted_mask = (predicted_mask > 0.5).astype(np.uint8)  # Apply a threshold to get a binary mask\n",
    "                    plt.imshow(binary_predicted_mask, cmap='gray')\n",
    "                    plt.title(f\"Predicted Mask for {image_file}\")\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "# Use the trained model to make predictions on all images\n",
    "predict_on_all_images(base_path, regressor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
